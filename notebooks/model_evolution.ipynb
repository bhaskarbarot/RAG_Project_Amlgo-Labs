{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2beed1b",
   "metadata": {},
   "source": [
    "#### Date 30th july 2025 Project Rag for AMLGO LABS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bfbfe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add parent directory to sys.path so `src` can be imported\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(project_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1585a0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Setting up comprehensive testing and evaluation...\n",
      "Initializing RAG pipeline...\n",
      "RAG pipeline initialized!\n",
      " Prepared 10 test queries\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "import json\n",
    "import pandas as pd\n",
    "from src.pipeline import RAGPipeline\n",
    "import time\n",
    "\n",
    "print(\" Setting up comprehensive testing and evaluation...\")\n",
    "\n",
    "# Load pipeline\n",
    "pipeline = RAGPipeline(\n",
    "    index_path=\"../vectordb/document_index.faiss\",\n",
    "    metadata_path=\"../vectordb/metadata.json\"\n",
    ")\n",
    "\n",
    "# Define comprehensive test queries\n",
    "test_queries = [\n",
    "    \"What are eBay's return policies for buyers?\",\n",
    "    \"How much fees does eBay charge sellers?\", \n",
    "    \"Can I cancel my order after purchasing?\",\n",
    "    \"What happens if I violate eBay's user agreement?\",\n",
    "    \"How does eBay handle disputes between buyers and sellers?\",\n",
    "    \"What information does eBay collect from users?\",\n",
    "    \"Are there any restrictions on what I can sell?\",\n",
    "    \"What is eBay's policy on intellectual property?\",\n",
    "    \"How does eBay's arbitration process work?\",\n",
    "    \"What are the payment terms for sellers?\"\n",
    "]\n",
    "\n",
    "print(f\" Prepared {len(test_queries)} test queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04250d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/petpooja/Documents/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Running comprehensive tests...\n",
      "============================================================\n",
      "\\nTest 1/10: What are eBay's return policies for buyers?\n",
      "----------------------------------------\n",
      "Response (0.06s): Error generating response: PreTrainedTokenizerFast._batch_encode_plus() got an unexpected keyword argument 'truncate'...\n",
      "Stats: 10 words, 3 sources\n",
      "\\nTest 2/10: How much fees does eBay charge sellers?\n",
      "----------------------------------------\n",
      "Response (0.04s): Error generating response: PreTrainedTokenizerFast._batch_encode_plus() got an unexpected keyword argument 'truncate'...\n",
      "Stats: 10 words, 3 sources\n",
      "\\nTest 3/10: Can I cancel my order after purchasing?\n",
      "----------------------------------------\n",
      "Response (0.03s): Error generating response: PreTrainedTokenizerFast._batch_encode_plus() got an unexpected keyword argument 'truncate'...\n",
      "Stats: 10 words, 3 sources\n",
      "\\nTest 4/10: What happens if I violate eBay's user agreement?\n",
      "----------------------------------------\n",
      "Response (0.01s): Error generating response: PreTrainedTokenizerFast._batch_encode_plus() got an unexpected keyword argument 'truncate'...\n",
      "Stats: 10 words, 3 sources\n",
      "\\nTest 5/10: How does eBay handle disputes between buyers and sellers?\n",
      "----------------------------------------\n",
      "Response (0.01s): Error generating response: PreTrainedTokenizerFast._batch_encode_plus() got an unexpected keyword argument 'truncate'...\n",
      "Stats: 10 words, 3 sources\n",
      "\\nTest 6/10: What information does eBay collect from users?\n",
      "----------------------------------------\n",
      "Response (0.01s): Error generating response: PreTrainedTokenizerFast._batch_encode_plus() got an unexpected keyword argument 'truncate'...\n",
      "Stats: 10 words, 3 sources\n",
      "\\nTest 7/10: Are there any restrictions on what I can sell?\n",
      "----------------------------------------\n",
      "Response (0.01s): Error generating response: PreTrainedTokenizerFast._batch_encode_plus() got an unexpected keyword argument 'truncate'...\n",
      "Stats: 10 words, 3 sources\n",
      "\\nTest 8/10: What is eBay's policy on intellectual property?\n",
      "----------------------------------------\n",
      "Response (0.01s): Error generating response: PreTrainedTokenizerFast._batch_encode_plus() got an unexpected keyword argument 'truncate'...\n",
      "Stats: 10 words, 3 sources\n",
      "\\nTest 9/10: How does eBay's arbitration process work?\n",
      "----------------------------------------\n",
      "Response (0.01s): Error generating response: PreTrainedTokenizerFast._batch_encode_plus() got an unexpected keyword argument 'truncate'...\n",
      "Stats: 10 words, 3 sources\n",
      "\\nTest 10/10: What are the payment terms for sellers?\n",
      "----------------------------------------\n",
      "Response (0.01s): Error generating response: PreTrainedTokenizerFast._batch_encode_plus() got an unexpected keyword argument 'truncate'...\n",
      "Stats: 10 words, 3 sources\n",
      "\\n All tests completed!\n"
     ]
    }
   ],
   "source": [
    "# Test all queries and collect results\n",
    "test_results = []\n",
    "\n",
    "print(\" Running comprehensive tests...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"\\\\nTest {i}/{len(test_queries)}: {query}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        response, sources = pipeline.query(query, top_k=3)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        # Evaluate response\n",
    "        result = {\n",
    "            'query_id': i,\n",
    "            'query': query,\n",
    "            'response': response,\n",
    "            'sources': sources,\n",
    "            'response_time': end_time - start_time,\n",
    "            'response_length': len(response),\n",
    "            'response_words': len(response.split()),\n",
    "            'num_sources': len(sources),\n",
    "            'success': True,\n",
    "            'grounded': len(sources) > 0,\n",
    "            'avg_source_length': sum(len(s) for s in sources) / len(sources) if sources else 0\n",
    "        }\n",
    "        \n",
    "        print(f\"Response ({result['response_time']:.2f}s): {response[:150]}...\")\n",
    "        print(f\"Stats: {result['response_words']} words, {result['num_sources']} sources\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        result = {\n",
    "            'query_id': i,\n",
    "            'query': query,\n",
    "            'response': f\"ERROR: {str(e)}\",\n",
    "            'sources': [],\n",
    "            'response_time': 0,\n",
    "            'response_length': 0,\n",
    "            'response_words': 0,\n",
    "            'num_sources': 0,\n",
    "            'success': False,\n",
    "            'grounded': False,\n",
    "            'avg_source_length': 0\n",
    "        }\n",
    "        print(f\" Error: {str(e)}\")\n",
    "    \n",
    "    test_results.append(result)\n",
    "\n",
    "print(\"\\\\n All tests completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7610c022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " COMPREHENSIVE TEST RESULTS\n",
      "==================================================\n",
      "\\nOverall Performance:\n",
      "Success Rate: 100.0%\n",
      "Average Response Time: 0.02 seconds\n",
      "Average Response Length: 10.0 words\n",
      "\\nSource Retrieval:\n",
      "Average Sources per Query: 3.0\n",
      "Grounded Responses: 10/10\n",
      "\\nResponse Statistics:\n",
      "Response Length Range: 10-10 words\n",
      "Response Time Range: 0.01-0.06 seconds\n",
      "\\nDETAILED RESULTS:\n",
      "==================================================\n",
      "\\n1. SUCCESS\n",
      "Query: What are eBay's return policies for buyers?\n",
      "Response: Error generating response: PreTrainedTokenizerFast._batch_encode_plus() got an unexpected keyword argument 'truncate'\n",
      "Time: 0.06s | Words: 10 | Sources: 3\n",
      "\\n2. SUCCESS\n",
      "Query: How much fees does eBay charge sellers?\n",
      "Response: Error generating response: PreTrainedTokenizerFast._batch_encode_plus() got an unexpected keyword argument 'truncate'\n",
      "Time: 0.04s | Words: 10 | Sources: 3\n",
      "\\n3. SUCCESS\n",
      "Query: Can I cancel my order after purchasing?\n",
      "Response: Error generating response: PreTrainedTokenizerFast._batch_encode_plus() got an unexpected keyword argument 'truncate'\n",
      "Time: 0.03s | Words: 10 | Sources: 3\n",
      "\\n4. SUCCESS\n",
      "Query: What happens if I violate eBay's user agreement?\n",
      "Response: Error generating response: PreTrainedTokenizerFast._batch_encode_plus() got an unexpected keyword argument 'truncate'\n",
      "Time: 0.01s | Words: 10 | Sources: 3\n",
      "\\n5. SUCCESS\n",
      "Query: How does eBay handle disputes between buyers and sellers?\n",
      "Response: Error generating response: PreTrainedTokenizerFast._batch_encode_plus() got an unexpected keyword argument 'truncate'\n",
      "Time: 0.01s | Words: 10 | Sources: 3\n",
      "\\n6. SUCCESS\n",
      "Query: What information does eBay collect from users?\n",
      "Response: Error generating response: PreTrainedTokenizerFast._batch_encode_plus() got an unexpected keyword argument 'truncate'\n",
      "Time: 0.01s | Words: 10 | Sources: 3\n",
      "\\n7. SUCCESS\n",
      "Query: Are there any restrictions on what I can sell?\n",
      "Response: Error generating response: PreTrainedTokenizerFast._batch_encode_plus() got an unexpected keyword argument 'truncate'\n",
      "Time: 0.01s | Words: 10 | Sources: 3\n",
      "\\n8. SUCCESS\n",
      "Query: What is eBay's policy on intellectual property?\n",
      "Response: Error generating response: PreTrainedTokenizerFast._batch_encode_plus() got an unexpected keyword argument 'truncate'\n",
      "Time: 0.01s | Words: 10 | Sources: 3\n",
      "\\n9. SUCCESS\n",
      "Query: How does eBay's arbitration process work?\n",
      "Response: Error generating response: PreTrainedTokenizerFast._batch_encode_plus() got an unexpected keyword argument 'truncate'\n",
      "Time: 0.01s | Words: 10 | Sources: 3\n",
      "\\n10. SUCCESS\n",
      "Query: What are the payment terms for sellers?\n",
      "Response: Error generating response: PreTrainedTokenizerFast._batch_encode_plus() got an unexpected keyword argument 'truncate'\n",
      "Time: 0.01s | Words: 10 | Sources: 3\n"
     ]
    }
   ],
   "source": [
    "# Create comprehensive analysis\n",
    "df_results = pd.DataFrame(test_results)\n",
    "\n",
    "# Success statistics\n",
    "success_rate = df_results['success'].mean() * 100\n",
    "avg_response_time = df_results[df_results['success']]['response_time'].mean()\n",
    "avg_response_length = df_results[df_results['success']]['response_words'].mean()\n",
    "\n",
    "print(\" COMPREHENSIVE TEST RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\\\nOverall Performance:\")\n",
    "print(f\"Success Rate: {success_rate:.1f}%\")\n",
    "print(f\"Average Response Time: {avg_response_time:.2f} seconds\")\n",
    "print(f\"Average Response Length: {avg_response_length:.1f} words\")\n",
    "\n",
    "print(f\"\\\\nSource Retrieval:\")\n",
    "print(f\"Average Sources per Query: {df_results['num_sources'].mean():.1f}\")\n",
    "print(f\"Grounded Responses: {df_results['grounded'].sum()}/{len(df_results)}\")\n",
    "\n",
    "print(f\"\\\\nResponse Statistics:\")\n",
    "successful_responses = df_results[df_results['success']]\n",
    "if len(successful_responses) > 0:\n",
    "    print(f\"Response Length Range: {successful_responses['response_words'].min()}-{successful_responses['response_words'].max()} words\")\n",
    "    print(f\"Response Time Range: {successful_responses['response_time'].min():.2f}-{successful_responses['response_time'].max():.2f} seconds\")\n",
    "\n",
    "# Display detailed results\n",
    "print(f\"\\\\nDETAILED RESULTS:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, result in enumerate(test_results, 1):\n",
    "    status = \"SUCCESS\" if result['success'] else \"FAILED\"\n",
    "    print(f\"\\\\n{i}. {status}\")\n",
    "    print(f\"Query: {result['query']}\")\n",
    "    print(f\"Response: {result['response'][:200]}{'...' if len(result['response']) > 200 else ''}\")\n",
    "    if result['success']:\n",
    "        print(f\"Time: {result['response_time']:.2f}s | Words: {result['response_words']} | Sources: {result['num_sources']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "265498b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS CASES ANALYSIS\n",
      "========================================\n",
      "\\nMost Comprehensive Responses:\n",
      "\\n• Query: What are eBay's return policies for buyers?\n",
      "  Response (10 words): Error generating response: PreTrainedTokenizerFast._batch_encode_plus() got an unexpected keyword argument 'truncate'...\n",
      "  Sources: 3\n",
      "\\n• Query: How much fees does eBay charge sellers?\n",
      "  Response (10 words): Error generating response: PreTrainedTokenizerFast._batch_encode_plus() got an unexpected keyword argument 'truncate'...\n",
      "  Sources: 3\n",
      "\\n• Query: Can I cancel my order after purchasing?\n",
      "  Response (10 words): Error generating response: PreTrainedTokenizerFast._batch_encode_plus() got an unexpected keyword argument 'truncate'...\n",
      "  Sources: 3\n",
      "\\nFAILURE CASES ANALYSIS\n",
      "========================================\n",
      "\\nNo failures detected!\n"
     ]
    }
   ],
   "source": [
    "# Analyze success and failure patterns\n",
    "successful_queries = df_results[df_results['success'] == True]\n",
    "failed_queries = df_results[df_results['success'] == False]\n",
    "\n",
    "print(\"SUCCESS CASES ANALYSIS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "if len(successful_queries) > 0:\n",
    "    # Best performing queries\n",
    "    best_queries = successful_queries.nlargest(3, 'response_words')\n",
    "    print(\"\\\\nMost Comprehensive Responses:\")\n",
    "    for _, row in best_queries.iterrows():\n",
    "        print(f\"\\\\n• Query: {row['query']}\")\n",
    "        print(f\"  Response ({row['response_words']} words): {row['response'][:150]}...\")\n",
    "        print(f\"  Sources: {row['num_sources']}\")\n",
    "\n",
    "print(\"\\\\nFAILURE CASES ANALYSIS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "if len(failed_queries) > 0:\n",
    "    print(\"\\\\nFailed Queries:\")\n",
    "    for _, row in failed_queries.iterrows():\n",
    "        print(f\"\\\\n• Query: {row['query']}\")\n",
    "        print(f\"  Error: {row['response']}\")\n",
    "else:\n",
    "    print(\"\\\\nNo failures detected!\")\n",
    "\n",
    "# Look for queries with poor responses (very short or generic)\n",
    "short_responses = successful_queries[successful_queries['response_words'] < 10]\n",
    "if len(short_responses) > 0:\n",
    "    print(\"\\nShort/Generic Responses (Potential Issues):\")\n",
    "    for _, row in short_responses.iterrows():\n",
    "        print(f\"\\n• Query: {row['query']}\")\n",
    "        print(f\"  Response ({row['response_words']} words): {row['response']}\")\n",
    "        print(f\"  Sources: {row['num_sources']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce19e69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results saved to ../test_results.json\n",
      "\n",
      "REPORT SUMMARY\n",
      "========================================\n",
      "\n",
      "## Testing Results Summary\n",
      "\n",
      "### Performance Metrics\n",
      "- **Total Test Queries**: 10\n",
      "- **Success Rate**: 100.0%\n",
      "- **Average Response Time**: 0.02 seconds\n",
      "- **Average Response Length**: 10.0 words\n",
      "- **Average Sources Retrieved**: 3.0\n",
      "\n",
      "### Example Successful Queries:\n",
      "\n",
      "\n",
      "**Example 1:**\n",
      "- **Query**: What are eBay's return policies for buyers?\n",
      "- **Response**: Error generating response: PreTrainedTokenizerFast._batch_encode_plus() got an unexpected keyword argument 'truncate'...\n",
      "- **Sources Used**: 3\n",
      "- **Response Time**: 0.06s\n",
      "\n",
      "**Example 2:**\n",
      "- **Query**: How much fees does eBay charge sellers?\n",
      "- **Response**: Error generating response: PreTrainedTokenizerFast._batch_encode_plus() got an unexpected keyword argument 'truncate'...\n",
      "- **Sources Used**: 3\n",
      "- **Response Time**: 0.04s\n",
      "\n",
      "**Example 3:**\n",
      "- **Query**: Can I cancel my order after purchasing?\n",
      "- **Response**: Error generating response: PreTrainedTokenizerFast._batch_encode_plus() got an unexpected keyword argument 'truncate'...\n",
      "- **Sources Used**: 3\n",
      "- **Response Time**: 0.03s\n",
      "\n",
      "Testing and evaluation complete!\n"
     ]
    }
   ],
   "source": [
    "# Save detailed test results\n",
    "results_to_save = {\n",
    "    'test_metadata': {\n",
    "        'total_queries': len(test_queries),\n",
    "        'success_rate': success_rate,\n",
    "        'avg_response_time': avg_response_time,\n",
    "        'avg_response_length': avg_response_length,\n",
    "        'test_date': str(pd.Timestamp.now())\n",
    "    },\n",
    "    'detailed_results': test_results\n",
    "}\n",
    "\n",
    "with open('../test_results.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(results_to_save, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"Test results saved to ../test_results.json\")\n",
    "\n",
    "# Generate summary for report\n",
    "print(\"\\nREPORT SUMMARY\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "print(f\"\"\"\n",
    "## Testing Results Summary\n",
    "\n",
    "### Performance Metrics\n",
    "- **Total Test Queries**: {len(test_queries)}\n",
    "- **Success Rate**: {success_rate:.1f}%\n",
    "- **Average Response Time**: {avg_response_time:.2f} seconds\n",
    "- **Average Response Length**: {avg_response_length:.1f} words\n",
    "- **Average Sources Retrieved**: {df_results['num_sources'].mean():.1f}\n",
    "\n",
    "### Example Successful Queries:\n",
    "\"\"\")\n",
    "\n",
    "# Show top 3 successful examples for report\n",
    "top_examples = successful_queries.nlargest(3, 'response_words')\n",
    "for i, (_, row) in enumerate(top_examples.iterrows(), 1):\n",
    "    print(f\"\\n**Example {i}:**\")\n",
    "    print(f\"- **Query**: {row['query']}\")\n",
    "    print(f\"- **Response**: {row['response'][:200]}...\")\n",
    "    print(f\"- **Sources Used**: {row['num_sources']}\")\n",
    "    print(f\"- **Response Time**: {row['response_time']:.2f}s\")\n",
    "\n",
    "if len(failed_queries) > 0:\n",
    "    print(f\"\\n### Failure Cases:\")\n",
    "    for _, row in failed_queries.iterrows():\n",
    "        print(f\"- **Query**: {row['query']}\")\n",
    "        print(f\"- **Issue**: {row['response']}\")\n",
    "\n",
    "print(\"\\nTesting and evaluation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a6b059",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
